# -*- coding: utf-8 -*-
"""Knn_SVM_classifiers.ipynb

Automatically generated by Colab.


## DL Project - Reading in Data

This is a script to read in the ACDC dataset. Download the dataset from this url:

https://humanheart-project.creatis.insa-lyon.fr/database/#collection/637218c173e9f0047faa00fb

Then edit the paths below to match where the training and testing data is (these folders should be located in the downloaded data). Currently extracting just 1 of the 7-9 images for each subject (note: the index is 2 bc index 0 didn't always have a gt with it), so this is something we can change if we need.

Should see 200 training images and 100 testing images.
"""

from google.colab import drive
drive.mount('/content/drive')

# Edit these variables to match your setup
dataset_path_training = '/content/drive/My Drive/python/Resources/training'
dataset_path_testing = '/content/drive/My Drive/python/Resources/testing'

# dataset_path_training = '/Users/calebhallinan/Desktop/jhu/classes/deep_learning/DL_Final_Project_2024/data/ACDC/training'
# dataset_path_testing = '/Users/calebhallinan/Desktop/jhu/classes/deep_learning/DL_Final_Project_2024/data/ACDC/testing'

### Import packages

import os
import nibabel as nib
import numpy as np
import re
from skimage.transform import resize
import configparser
import pandas as pd


### Functions to load in the data ###

# Regular expression to extract the patient number and frame number from filenames
filename_pattern = re.compile(r'patient(\d+)_frame(\d+)(_gt)?\.nii\.gz')

# Function to get sorting key from the filename
def get_sort_key(filepath):
    match = filename_pattern.search(os.path.basename(filepath))
    if match:
        patient_num = int(match.group(1))
        frame_num = int(match.group(2))
        return (patient_num, frame_num)
    else:
        raise ValueError(f'Filename does not match expected pattern: {filepath}')

    # Function to extract the patient number and sort by it
def extract_patient_number(file_path):
    match = re.search(r"patient(\d+)", file_path)
    return int(match.group(1)) if match else None

# Lists to hold the file paths for images and ground truths
image_file_paths_train = []
ground_truth_file_paths_train = []
class_file_paths_train = []

# Walk through the directory and collect all relevant file paths
for root, dirs, files in os.walk(dataset_path_training):
    for file in files:
        if 'frame' in file:
            full_path = os.path.join(root, file)
            if '_gt' in file:
                ground_truth_file_paths_train.append(full_path)
            else:
                image_file_paths_train.append(full_path)
        if "Info" in file:
            class_file_paths_train.append(os.path.join(root, file))


# Sort the file paths to ensure alignment
image_file_paths_train.sort(key=get_sort_key)
ground_truth_file_paths_train.sort(key=get_sort_key)
class_file_paths_train = sorted(class_file_paths_train, key=extract_patient_number)

# Check to make sure each image has a corresponding ground truth
assert len(image_file_paths_train) == len(ground_truth_file_paths_train)
for img_path, gt_path in zip(image_file_paths_train, ground_truth_file_paths_train):
    assert get_sort_key(img_path) == get_sort_key(gt_path), "Mismatch between image and ground truth files"

# Extract the class labels from the config files
class_labels_train = []
for class_file in class_file_paths_train:
        config = pd.read_csv(class_file, sep=':', header=None)
        class_labels_train.append(config[config[0] == "Group"][1][2].strip())
        class_labels_train.append(config[config[0] == "Group"][1][2].strip()) # doing twice bc there are 2 files per patient

# Load the images and ground truths into numpy arrays
# using 2 index bc not all 0 index had a gt
images_train = [resize(nib.load(path).get_fdata()[:,:,2], (224,224)) for path in image_file_paths_train]
ground_truths_train = [resize(nib.load(path).get_fdata()[:,:,2], (224,224)) for path in ground_truth_file_paths_train]

# Stack the arrays into 4D numpy arrays
images_array_train = np.stack(images_train)
ground_truths_array_train = np.stack(ground_truths_train)

print(f'Training Images array shape: {images_array_train.shape}')
print(f'Training Ground truths array shape: {ground_truths_array_train.shape}')
print(f'Class labels: {class_labels_train}', '\n', "Total Class Labels: ",len(class_labels_train))


### Read in testing data ###

# Lists to hold the file paths for images and ground truths
image_file_paths_test = []
ground_truth_file_paths_test = []
class_file_paths_test = []

# Walk through the directory and collect all relevant file paths
for root, dirs, files in os.walk(dataset_path_testing):
    for file in files:
        if 'frame' in file:
            full_path = os.path.join(root, file)
            if '_gt' in file:
                ground_truth_file_paths_test.append(full_path)
            else:
                image_file_paths_test.append(full_path)
        if "Info" in file:
            class_file_paths_test.append(os.path.join(root, file))

# Sort the file paths to ensure alignment
image_file_paths_test.sort(key=get_sort_key)
ground_truth_file_paths_test.sort(key=get_sort_key)
class_file_paths_test = sorted(class_file_paths_test, key=extract_patient_number)

# Check to make sure each image has a corresponding ground truth
assert len(image_file_paths_test) == len(ground_truth_file_paths_test)
for img_path, gt_path in zip(image_file_paths_test, ground_truth_file_paths_test):
    assert get_sort_key(img_path) == get_sort_key(gt_path), "Mismatch between image and ground truth files"

# Extract the class labels from the config files
class_labels_test = []
for class_file in class_file_paths_test:
        config = pd.read_csv(class_file, sep=':', header=None)
        class_labels_test.append(config[config[0] == "Group"][1][2].strip())
        class_labels_test.append(config[config[0] == "Group"][1][2].strip())


# Load the images and ground truths into numpy arrays
# using 2 index bc not all 0 index had a gt
images_test = [resize(nib.load(path).get_fdata()[:,:,2], (224,224)) for path in image_file_paths_test]
ground_truths_test = [resize(nib.load(path).get_fdata()[:,:,2], (224,224)) for path in ground_truth_file_paths_test]

# Stack the arrays into 4D numpy arrays
images_array_test = np.stack(images_test)
ground_truths_array_test = np.stack(ground_truths_test)

print(f'Test Images array shape: {images_array_test.shape}')
print(f'Test Ground truths array shape: {ground_truths_array_test.shape}')
print(f'Class labels: {class_labels_test}', '\n', "Total Class Labels: ",len(class_labels_test))

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.model_selection import GridSearchCV
from sklearn.utils import shuffle

# Shuffle the training data
images_flattened_train, class_labels_train = shuffle(images_flattened_train, class_labels_train)

# Feature Scaling
scaler = StandardScaler()
images_scaled_train = scaler.fit_transform(images_flattened_train)
images_scaled_test = scaler.transform(images_flattened_test)

# Feature Engineering with PCA
pca = PCA(n_components=10)  # Experiment with the number of components
images_pca_train = pca.fit_transform(images_scaled_train)
images_pca_test = pca.transform(images_scaled_test)

# Hyperparameter Tuning for KNN
knn_param_grid = {'n_neighbors': [3, 5, 7, 9]}  # Define the grid of parameters
knn_classifier_tuned = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=5)  # Perform grid search cross-validation
knn_classifier_tuned.fit(images_pca_train, class_labels_train)

# Hyperparameter Tuning for SVM
svm_param_grid = {'C': [0.1, 1,10], 'kernel': ['linear', 'rbf']}  # Define the grid of parameters
svm_classifier_tuned = GridSearchCV(SVC(), svm_param_grid, cv=5)  # Perform grid search cross-validation
svm_classifier_tuned.fit(images_pca_train, class_labels_train)

# Evaluate tuned classifiers
knn_predictions_tuned = knn_classifier_tuned.predict(images_pca_test)
svm_predictions_tuned = svm_classifier_tuned.predict(images_pca_test)

# Calculate accuracy scores for tuned classifiers
knn_accuracy_tuned = accuracy_score(class_labels_test, knn_predictions_tuned)
svm_accuracy_tuned = accuracy_score(class_labels_test, svm_predictions_tuned)

# Print classification reports for tuned classifiers
print("Tuned KNN Classification Report:")
print(classification_report(class_labels_test, knn_predictions_tuned))
print("Tuned SVM Classification Report:")
print(classification_report(class_labels_test, svm_predictions_tuned))

# prompt: best params for finetune knn and svm

# Best parameters for KNN after tuning
knn_best_params = knn_classifier_tuned.best_params_
print("Best parameters for KNN:", knn_best_params)

# Best parameters for SVM after tuning
svm_best_params = svm_classifier_tuned.best_params_
print("Best parameters for SVM:", svm_best_params)

# Get unique class labels
unique_labels = np.unique(class_labels_test)

# Reorder class labels based on the order of unique labels in the confusion matrices
ordered_labels_knn = [label for label in knn_cm_tuned.sum(axis=0).argsort()]
ordered_labels_svm = [label for label in svm_cm_tuned.sum(axis=0).argsort()]

# Map original class labels to reordered labels
reordered_class_labels_test_knn = [unique_labels[label] for label in ordered_labels_knn]
reordered_class_labels_test_svm = [unique_labels[label] for label in ordered_labels_svm]

# Plot confusion matrices for tuned classifiers with reordered labels
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
sns.heatmap(knn_cm_tuned, annot=True, fmt="d", cmap="Blues", xticklabels=reordered_class_labels_test_knn, yticklabels=reordered_class_labels_test_knn)
plt.title("Tuned KNN Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")

plt.subplot(1, 2, 2)
sns.heatmap(svm_cm_tuned, annot=True, fmt="d", cmap="Blues", xticklabels=reordered_class_labels_test_svm, yticklabels=reordered_class_labels_test_svm)
plt.title("Tuned SVM Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")

plt.tight_layout()
plt.show()

